{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DesignOptimizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4532774a2b344da7996220d599d55d87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b1fb9a2f757b4cd78592c3ffe430972d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_491ec30c7dc349ff94ecc18126034fb0",
              "IPY_MODEL_e9300fe1ad4143f3a048d76160c25e80"
            ]
          }
        },
        "b1fb9a2f757b4cd78592c3ffe430972d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "491ec30c7dc349ff94ecc18126034fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1a967c8e72c34a9f8b3bd9c1b2aefeb4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4fd5925050e84f6db69d289e440f0874"
          }
        },
        "e9300fe1ad4143f3a048d76160c25e80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4108b4971a334084bce04fb3d7e9f09b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 85390520.96it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b069dd7de3f4f0a9c4dff62a33ad5cd"
          }
        },
        "1a967c8e72c34a9f8b3bd9c1b2aefeb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4fd5925050e84f6db69d289e440f0874": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4108b4971a334084bce04fb3d7e9f09b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5b069dd7de3f4f0a9c4dff62a33ad5cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1T_gGTh_hSS"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from torch.optim.optimizer import Optimizer"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTb3yiXBvqnt"
      },
      "source": [
        "version_higher = ( torch.__version__ >= \"1.5.0\" )\n",
        "\n",
        "class NestAdam(Optimizer):\n",
        "    def __init__(self, params, lr=1e-03, betas=(0.9, 0.999), eps=1e-16,\n",
        "                 weight_decay=0, amsgrad=False, weight_decouple=True, fixed_decay=False,\n",
        "                 rectify=True, degenerated_to_sgd=True):\n",
        "        if not 0.0 <= lr:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
        "        if not 0.0 <= weight_decay:\n",
        "            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n",
        "        \n",
        "        if isinstance(params, (list, tuple)) and len(params) > 0 and isinstance(params[0], dict):\n",
        "            for param in params:\n",
        "                if 'betas' in param and (param['betas'][0] != betas[0] or param['betas'][1] != betas[1]):\n",
        "                    param['buffer'] = [[None, None, None] for _ in range(10)]\n",
        "\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
        "                        weight_decay=weight_decay, amsgrad=amsgrad, buffer=[[None, None, None] for _ in range(10)])\n",
        "        super(NestAdam, self).__init__(params, defaults)\n",
        "\n",
        "        self.degenerated_to_sgd = degenerated_to_sgd\n",
        "        self.weight_decouple = weight_decouple\n",
        "        self.rectify = rectify\n",
        "        self.fixed_decay = fixed_decay\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(NestAdam, self).__setstate__(state)\n",
        "        for group in self.param_groups:\n",
        "            group.setdefault('amsgrad', False)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "        Arguments:\n",
        "            closure (callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError(\n",
        "                        'NestAdam does not support sparse gradients, please consider SparseAdam instead')\n",
        "                amsgrad = group['amsgrad']\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                # State initialization\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    # Exponential moving average of gradient values\n",
        "                    state['exp_avg'] = torch.zeros_like(p.data,memory_format=torch.preserve_format) \\\n",
        "                        if version_higher else torch.zeros_like(p.data)\n",
        "                    # Exponential moving average of squared gradient values\n",
        "                    state['exp_avg_var'] = torch.zeros_like(p.data,memory_format=torch.preserve_format) \\\n",
        "                        if version_higher else torch.zeros_like(p.data)\n",
        "                    if amsgrad:\n",
        "                        # Maintains max of all exp. moving avg. of sq. grad. values\n",
        "                        state['max_exp_avg_var'] = torch.zeros_like(p.data,memory_format=torch.preserve_format) \\\n",
        "                            if version_higher else torch.zeros_like(p.data)\n",
        "\n",
        "                # get current state variable\n",
        "                exp_avg, exp_avg_var = state['exp_avg'], state['exp_avg_var']\n",
        "\n",
        "                state['step'] += 1\n",
        "                bias_correction1 = 1 - beta1 ** state['step']\n",
        "                bias_correction2 = 1 - beta2 ** state['step']\n",
        "\n",
        "                # Approximate Nesterov's Accelerated Gradient\n",
        "                v = exp_avg.mul(beta1).add(grad, alpha=1 - beta1)\n",
        "                grad.mul_(1 - beta1).add_(v, alpha=beta1)\n",
        "                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n",
        "                # exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n",
        "                # grad.mul_(1 - beta1).add_(exp_avg, alpha=beta1)\n",
        "\n",
        "                # Update first and second moment running average\n",
        "                grad_residual = grad - exp_avg\n",
        "                exp_avg_var.mul_(beta2).addcmul_(grad_residual, grad_residual, value=1 - beta2)\n",
        "\n",
        "                if amsgrad:\n",
        "                    max_exp_avg_var = state['max_exp_avg_var']\n",
        "                    # Maintains the maximum of all 2nd moment running avg. till now\n",
        "                    torch.max(max_exp_avg_var, exp_avg_var, out=max_exp_avg_var)\n",
        "\n",
        "                    # Use the max. for normalizing running avg. of gradient\n",
        "                    denom = (max_exp_avg_var.add_(group['eps']).sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])\n",
        "                else:\n",
        "                    denom = (exp_avg_var.add_(group['eps']).sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])\n",
        "\n",
        "                # perform weight decay, check if decoupled weight decay\n",
        "                if self.weight_decouple:\n",
        "                    if not self.fixed_decay:\n",
        "                        p.data.mul_(1.0 - group['lr'] * group['weight_decay'])\n",
        "                    else:\n",
        "                        p.data.mul_(1.0 - group['weight_decay'])\n",
        "                else:\n",
        "                    if group['weight_decay'] != 0:\n",
        "                        grad.add_(p.data, alpha=group['weight_decay'])\n",
        "\n",
        "                # update\n",
        "                if not self.rectify:\n",
        "                    # Default update\n",
        "                    step_size = group['lr'] / bias_correction1\n",
        "                    p.data.addcdiv_( exp_avg, denom, value=-step_size)\n",
        "\n",
        "                else:  # Rectified update, forked from RAdam\n",
        "                    buffered = group['buffer'][int(state['step'] % 10)]\n",
        "                    if state['step'] == buffered[0]:\n",
        "                        N_sma, step_size = buffered[1], buffered[2]\n",
        "                    else:\n",
        "                        buffered[0] = state['step']\n",
        "                        beta2_t = beta2 ** state['step']\n",
        "                        N_sma_max = 2 / (1 - beta2) - 1\n",
        "                        N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
        "                        buffered[1] = N_sma\n",
        "\n",
        "                        # more conservative since it's an approximated value\n",
        "                        if N_sma >= 5:\n",
        "                            step_size = math.sqrt(\n",
        "                                (1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (\n",
        "                                        N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
        "                        elif self.degenerated_to_sgd:\n",
        "                            step_size = 1.0 / (1 - beta1 ** state['step'])\n",
        "                        else:\n",
        "                            step_size = -1\n",
        "                        buffered[2] = step_size\n",
        "\n",
        "                    if N_sma >= 5:\n",
        "                        denom = exp_avg_var.sqrt().add_(group['eps'])\n",
        "                        p.data.addcdiv_(exp_avg, denom, value=-step_size * group['lr'])\n",
        "                    elif step_size > 0:\n",
        "                        p.data.add_( exp_avg, alpha=-step_size * group['lr'])\n",
        "\n",
        "        return loss"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idIPQkk_Ic2y"
      },
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYtO9TD5IsWG"
      },
      "source": [
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "train_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.RandomResizedCrop(224), \n",
        "                                      transforms.RandomHorizontalFlip(), \n",
        "                                      transforms.ToTensor(),\n",
        "                                      normalize])\n",
        "test_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                     transforms.CenterCrop(224),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     normalize])"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "4532774a2b344da7996220d599d55d87",
            "b1fb9a2f757b4cd78592c3ffe430972d",
            "491ec30c7dc349ff94ecc18126034fb0",
            "e9300fe1ad4143f3a048d76160c25e80",
            "1a967c8e72c34a9f8b3bd9c1b2aefeb4",
            "4fd5925050e84f6db69d289e440f0874",
            "4108b4971a334084bce04fb3d7e9f09b",
            "5b069dd7de3f4f0a9c4dff62a33ad5cd"
          ]
        },
        "id": "pYX_Z4qaIuyJ",
        "outputId": "855fc067-1df4-47ff-f6e1-e575b2077308"
      },
      "source": [
        "batch_size = 100\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=train_transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=test_transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4532774a2b344da7996220d599d55d87",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUI8U0FNIwn3"
      },
      "source": [
        "import time\n",
        "\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = s // 60\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD22rDMtIzQl"
      },
      "source": [
        "import torchvision.models as models"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqKEZsWEI1Ll"
      },
      "source": [
        "def evaluateImageModel(model, data, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for image, labels in data:\n",
        "            image, labels = image.to(device), labels.to(device)\n",
        "            output = model(image)\n",
        "            pred = torch.argmax(output, dim=1)\n",
        "            correct += (pred == labels).sum().item()\n",
        "            total += len(labels)\n",
        "            loss = criterion(output, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(data), 1 - correct / total\n",
        "\n",
        "def trainImageModel(model, train_data, val_data, n_epochs, criterion, optimizer, device, path):\n",
        "    model.train()\n",
        "    train_error_list = []\n",
        "    val_error_list = []\n",
        "    min_error = None\n",
        "    step = 0\n",
        "    print_every = len(train_data)\n",
        "    start = time.time()\n",
        "    for epoch in range(n_epochs):\n",
        "        running_loss = 0.0\n",
        "        running_correct = 0\n",
        "        running_total = 0\n",
        "        for image, labels in train_data:\n",
        "            optimizer.zero_grad()\n",
        "            step += 1\n",
        "            image, labels = image.to(device), labels.to(device)\n",
        "            output = model(image)\n",
        "            pred = torch.argmax(output, dim=1)\n",
        "            running_correct += (pred == labels).sum().item()\n",
        "            running_total += len(labels)\n",
        "            loss = criterion(output, labels)\n",
        "            running_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if step % print_every == 0:\n",
        "                val_loss, val_error = evaluateImageModel(model, val_data, criterion, device)\n",
        "                print(('%d/%d (%s) train loss: %.3f, train error: %.2f%%, val loss: %.3f, val error: %.2f%%') %\n",
        "                      (epoch + 1, n_epochs, timeSince(start), running_loss / len(train_data), \n",
        "                       100 *(1 - running_correct / running_total), val_loss, 100 * val_error))\n",
        "                train_error_list.append(1 - running_correct / running_total)\n",
        "                val_error_list.append(val_error)\n",
        "                if min_error is None or min_error > val_error:\n",
        "                    if min_error is None:\n",
        "                        print(('Validation error rate in first epoch: %.2f%%') % (100 * val_error))\n",
        "                    else:\n",
        "                        print(('Validation error rate is decreasing: %.2f%% --> %.2f%%') % \n",
        "                              (100 * min_error, 100 * val_error))\n",
        "                    min_error = val_error\n",
        "                    print('Saving model...')\n",
        "                    torch.save(model, path)\n",
        "                \n",
        "                model.train()\n",
        "                running_loss = 0.0\n",
        "                running_correct = 0\n",
        "                running_total = 0\n",
        "    \n",
        "    return train_error_list, val_error_list"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-XyzTA52I51B",
        "outputId": "5a0e7339-8292-45d9-c52d-92b4d08d9efd"
      },
      "source": [
        "model = models.resnet34()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "n_epochs = 50\n",
        "nadam_Res_train_list = None\n",
        "nadam_Res_test_list = None\n",
        "optimizer = NestAdam(model.parameters())\n",
        "model.to(device)\n",
        "path = 'nadamRes.pt'\n",
        "nadam_Res_train_list, nadam_Res_test_list = trainImageModel(model, trainloader, testloader,\n",
        "                                                                    n_epochs, criterion, optimizer,\n",
        "                                                                    device, path)\n",
        "torch.save(nadam_Res_train_list, 'nadamres_train.pt')\n",
        "torch.save(nadam_Res_test_list, 'nadamres_test.pt')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/50 (2m 49s) train loss: 2.058, train error: 70.78%, val loss: 1.634, val error: 60.43%\n",
            "Validation error rate in first epoch: 60.43%\n",
            "Saving model...\n",
            "2/50 (5m 39s) train loss: 1.685, train error: 61.83%, val loss: 1.499, val error: 55.53%\n",
            "Validation error rate is decreasing: 60.43% --> 55.53%\n",
            "Saving model...\n",
            "3/50 (8m 28s) train loss: 1.452, train error: 52.28%, val loss: 1.388, val error: 50.15%\n",
            "Validation error rate is decreasing: 55.53% --> 50.15%\n",
            "Saving model...\n",
            "4/50 (11m 17s) train loss: 1.296, train error: 46.50%, val loss: 1.027, val error: 35.97%\n",
            "Validation error rate is decreasing: 50.15% --> 35.97%\n",
            "Saving model...\n",
            "5/50 (14m 7s) train loss: 1.169, train error: 41.72%, val loss: 0.985, val error: 33.17%\n",
            "Validation error rate is decreasing: 35.97% --> 33.17%\n",
            "Saving model...\n",
            "6/50 (16m 55s) train loss: 1.075, train error: 37.96%, val loss: 0.851, val error: 28.69%\n",
            "Validation error rate is decreasing: 33.17% --> 28.69%\n",
            "Saving model...\n",
            "7/50 (19m 44s) train loss: 1.009, train error: 35.51%, val loss: 0.665, val error: 23.49%\n",
            "Validation error rate is decreasing: 28.69% --> 23.49%\n",
            "Saving model...\n",
            "8/50 (22m 33s) train loss: 0.928, train error: 32.60%, val loss: 0.624, val error: 21.65%\n",
            "Validation error rate is decreasing: 23.49% --> 21.65%\n",
            "Saving model...\n",
            "9/50 (25m 22s) train loss: 0.884, train error: 30.78%, val loss: 0.621, val error: 21.09%\n",
            "Validation error rate is decreasing: 21.65% --> 21.09%\n",
            "Saving model...\n",
            "10/50 (28m 10s) train loss: 0.847, train error: 29.63%, val loss: 0.559, val error: 19.46%\n",
            "Validation error rate is decreasing: 21.09% --> 19.46%\n",
            "Saving model...\n",
            "11/50 (30m 59s) train loss: 0.798, train error: 28.04%, val loss: 0.542, val error: 18.79%\n",
            "Validation error rate is decreasing: 19.46% --> 18.79%\n",
            "Saving model...\n",
            "12/50 (33m 48s) train loss: 0.757, train error: 26.52%, val loss: 0.495, val error: 16.74%\n",
            "Validation error rate is decreasing: 18.79% --> 16.74%\n",
            "Saving model...\n",
            "13/50 (36m 36s) train loss: 0.733, train error: 25.71%, val loss: 0.471, val error: 15.66%\n",
            "Validation error rate is decreasing: 16.74% --> 15.66%\n",
            "Saving model...\n",
            "14/50 (39m 24s) train loss: 0.695, train error: 24.35%, val loss: 0.430, val error: 14.52%\n",
            "Validation error rate is decreasing: 15.66% --> 14.52%\n",
            "Saving model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-91144fbd472b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m nadam_Res_train_list, nadam_Res_test_list = trainImageModel(model, trainloader, testloader,\n\u001b[1;32m     11\u001b[0m                                                                     \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                                                     device, path)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnadam_Res_train_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nadamres_train.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnadam_Res_test_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nadamres_test.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-efcbf0359cba>\u001b[0m in \u001b[0;36mtrainImageModel\u001b[0;34m(model, train_data, val_data, n_epochs, criterion, optimizer, device, path)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mrunning_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mrunning_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;34m\"\"\"Whether there is any input available to be read\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V59g9PkJchn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}