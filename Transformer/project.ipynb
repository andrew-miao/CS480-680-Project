{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUo4_yooRC8G",
        "outputId": "32e24278-5cf6-4831-b14e-d49ca5833c5e"
      },
      "source": [
        "!pip install spacy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7NK-CXARKLv"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRbXFcYtRMyy",
        "outputId": "aedd4fec-084c-41bb-fa69-01ceea229de1"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (50.3.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbsBtT5HR-y2",
        "outputId": "fe97a9b3-424a-4441-988c-eae7c73bcf57"
      },
      "source": [
        "!python -m spacy download de"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: de_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz#egg=de_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (50.3.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.11.8)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoizEzGs5xBv",
        "outputId": "d6d9c8ed-e17d-4b9d-d1fd-a9fde4e821bb"
      },
      "source": [
        "pip install torchtext"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.7.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torchtext) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torchtext) (0.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsgpDkyogrzG",
        "outputId": "b9a5b604-783a-4baa-a9f8-02bcae1bcf47"
      },
      "source": [
        "import spacy\n",
        "from torchtext.data import Field\n",
        "from torchtext.datasets import Multi30k, WMT14\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "spacy_de = spacy.load('de')\n",
        "spacy_en = spacy.load('en')\n",
        "\n",
        "BOS= '<s>'\n",
        "EOS = '</s>'\n",
        "PAD = '<pad>'\n",
        "\n",
        "def tokenize_de(text):\n",
        "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "def buildTensor(dataset, max_seq, src_vocab2num, trg_vocab2num, train=True, dev=False, test=False):\n",
        "    src_data = torch.ones(len(dataset), max_seq + 2)\n",
        "    trg_data = None\n",
        "    if not train:\n",
        "        raw_trg = []\n",
        "    \n",
        "    trg_data = torch.ones(len(dataset), max_seq + 2)\n",
        "\n",
        "    for i, sentence in enumerate(dataset):\n",
        "        src_data[i][0] = src_vocab2num[BOS]\n",
        "        src_data[i][-1] = trg_vocab2num[EOS]\n",
        "        for j in range(1, min(max_seq + 1, len(sentence.src))):\n",
        "            word = sentence.src[j - 1]\n",
        "            src_data[i][j] = src_vocab2num[word]\n",
        "\n",
        "        if trg_data is not None:\n",
        "            trg_data[i][0] = trg_vocab2num[BOS]\n",
        "            trg_data[i][-1] = trg_vocab2num[EOS]\n",
        "            for j in range(1, min(max_seq + 1, len(sentence.trg))):\n",
        "                word = sentence.trg[j - 1]\n",
        "                trg_data[i][j] = trg_vocab2num[word]\n",
        "\n",
        "            if not train:\n",
        "                raw_trg.append(sentence.trg)\n",
        "\n",
        "    if train:\n",
        "        return src_data, trg_data\n",
        "\n",
        "    elif dev:\n",
        "        return src_data, trg_data, raw_trg\n",
        "\n",
        "    else:\n",
        "        return src_data, raw_trg\n",
        "\n",
        "print('Loading dataset')\n",
        "\n",
        "SRC = Field(tokenize=tokenize_en, pad_token=PAD)\n",
        "TGT = Field(tokenize=tokenize_de, init_token=BOS, eos_token = EOS, pad_token=PAD)\n",
        "max_seq = 50\n",
        "train, dev, test = Multi30k.splits(exts=('.en', '.de'), fields=(SRC, TGT), filter_pred=lambda x: len(vars(x)['src']) <= max_seq and len(vars(x)['trg']) <= max_seq)\n",
        "\n",
        "min_freq = 2\n",
        "batch_size = 100\n",
        "SRC.build_vocab(train.src, min_freq=min_freq)\n",
        "TGT.build_vocab(train.trg, min_freq=min_freq)\n",
        "\n",
        "src_vocab = SRC.vocab\n",
        "trg_vocab = TGT.vocab\n",
        "\n",
        "src_train_data, trg_train_data = buildTensor(train, max_seq, src_vocab.stoi, trg_vocab.stoi, train=True)\n",
        "src_dev_data, trg_dev_data, raw_dev_trg = buildTensor(dev, max_seq, src_vocab.stoi, trg_vocab.stoi, train=False, dev=True)\n",
        "src_test_data, raw_test_trg = buildTensor(test, max_seq, src_vocab.stoi, trg_vocab.stoi, train=False, test=True)\n",
        "\n",
        "src_train_data, trg_train_data = src_train_data.type(torch.long), trg_train_data.type(torch.long)\n",
        "src_dev_data, trg_dev_data = src_dev_data.type(torch.long), trg_dev_data.type(torch.long)\n",
        "src_test_data = src_test_data.type(torch.long)\n",
        "\n",
        "print('Building dataset')\n",
        "train = TensorDataset(src_train_data, trg_train_data)\n",
        "dev = TensorDataset(src_dev_data, trg_dev_data)\n",
        "test = TensorDataset(src_test_data)\n",
        "\n",
        "print('Building dataloader')\n",
        "train_loader = DataLoader(train, batch_size=batch_size, pin_memory=True)\n",
        "dev_loader = DataLoader(dev, batch_size=batch_size, pin_memory=True)\n",
        "test_loader = DataLoader(test, batch_size=batch_size, pin_memory=True)\n",
        "\n",
        "print('Saving dataloader')\n",
        "torch.save(src_vocab.stoi, 'src_vocab2num.pt')\n",
        "torch.save(src_vocab.itos, 'src_num2vocab.pt')\n",
        "torch.save(trg_vocab.stoi, 'trg_vocab2num.pt')\n",
        "torch.save(trg_vocab.itos, 'trg_num2vocab.pt')\n",
        "torch.save(raw_dev_trg, 'raw_dev_trg.pt')\n",
        "torch.save(raw_test_trg, 'raw_test_trg.pt')\n",
        "torch.save(train_loader, 'train_loader.pt')\n",
        "torch.save(dev_loader, 'dev_loader.pt')\n",
        "torch.save(test_loader, 'test_loader.pt')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rtraining.tar.gz:   0%|          | 0.00/1.21M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset\n",
            "downloading training.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:00<00:00, 6.15MB/s]\n",
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 1.82MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n",
            "downloading mmt_task1_test2016.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 1.70MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Building dataset\n",
            "Building dataloader\n",
            "Saving dataloader\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0ooXN2J7YTF"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln4O5JTr2Gkd"
      },
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, n_src_vocab, n_trg_vocab, d_model=512, n_heads=8, n_encoders=6, n_decoders=6, d_ff=2048, dropout=0.1, padding_idx=1):\n",
        "        super(TransformerModel, self).__init__()\n",
        "\n",
        "        self.src_embedding = nn.Embedding(n_src_vocab, d_model, padding_idx=padding_idx)\n",
        "        self.trg_embedding = nn.Embedding(n_trg_vocab, d_model, padding_idx=padding_idx)\n",
        "        self.transformer = Transformer(d_model, n_heads, num_encoder_layers=n_encoders, num_decoder_layers=n_decoders,\n",
        "                                       dim_feedforward=d_ff, dropout=dropout)\n",
        "        self.fc = nn.Linear(d_model, n_trg_vocab)\n",
        "\n",
        "    def no_peek_mask(self, size):\n",
        "        mask = (torch.triu(torch.ones(size, size)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask.to(device)\n",
        "    \n",
        "    def forward(self, src_seq, trg_seq):\n",
        "        trg_mask = self.no_peek_mask(trg_seq.size(1))\n",
        "        src_seq, trg_seq = self.src_embedding(src_seq), self.trg_embedding(trg_seq)\n",
        "        src_seq, trg_seq = src_seq.permute(1, 0, 2), trg_seq.permute(1, 0, 2)  # size = (S, B, E), where S = max_seq, B = batch_size, E = embedding_size.\n",
        "        output = self.transformer(src_seq, trg_seq, tgt_mask=trg_mask)\n",
        "        return self.fc(output).permute(1, 2, 0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcLYUn5M2g4_"
      },
      "source": [
        "class TransformerOptim():\n",
        "    def __init__(self, optimizer, d_model=512, warmup_steps=4000):\n",
        "        \"\"\"\n",
        "        :param optimizer: the optimizer that we used, in the original paper, Vaswani et al. use Adam.\n",
        "        :param d_model: the embedding dimension.\n",
        "        :param warmup_steps: the number of warm up training steps.\n",
        "        \"\"\"\n",
        "        self.optimizer = optimizer\n",
        "        self.d_model = d_model\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.n_steps = 0\n",
        "\n",
        "    def update_lr(self):\n",
        "        \"\"\"\n",
        "        Updated learning rate. lr := d_model^(-0.5) * min(step_num^(-0.5), step_num * warmup_steps^(-1.5))\n",
        "        \"\"\"\n",
        "        self.n_steps += 1\n",
        "        lr = self.d_model**(-0.5) * min(self.n_steps**(-0.5), self.n_steps * self.warmup_steps**(-1.5))\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "    def zero_grad(self):\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "    def step(self):\n",
        "        self.update_lr()\n",
        "        self.optimizer.step()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDYFUO1shoEQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03908bbd-5f0a-4792-8e21-899ef3bc46d4"
      },
      "source": [
        "\"\"\"\n",
        "Author: Yanting Miao\n",
        "\"\"\"\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "def embedding(x, n_vocab, device, d_model=512):\n",
        "    embed = nn.Embedding(n_vocab, d_model, padding_idx=0).to(device)\n",
        "    return embed(x).permute(1, 0, 2)\n",
        "\n",
        "def calculate_time(start):\n",
        "    end = time.time()\n",
        "    t = end - start\n",
        "    m = t // 60\n",
        "    s = t - m * 60\n",
        "    return m, s\n",
        "\n",
        "def evaluating(model, data, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for src, trg in data:\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "            trg_input = trg[:, :-1]\n",
        "            trg_real = trg[:, 1:]\n",
        "            translate = model(src, trg_input)\n",
        "            loss = criterion(translate, trg_real)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(data)\n",
        "\n",
        "def training(model, train_data, dev_data, n_epochs, criterion, optimizer, device, path):\n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "    model.train()\n",
        "    step = 1\n",
        "    print_every = len(train_data)\n",
        "    min_loss = None\n",
        "    start = time.time()\n",
        "    for epoch in range(n_epochs):\n",
        "        running_loss = 0.0\n",
        "        for src, trg in train_data:\n",
        "            optimizer.zero_grad()\n",
        "            src = src.to(device)\n",
        "            # shifted to right, for example, trg = \"<s>I love cats</s>\", trg_input = \"<s>I love cats\", trg_real = \"I love cats</s>\"\n",
        "            trg_input = trg[:, :-1].to(device)\n",
        "            trg_real = trg[:, 1:].to(device)\n",
        "            translate = model(src, trg_input)\n",
        "            loss = criterion(translate, trg_real)\n",
        "            running_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            step += 1\n",
        "            if step % print_every == 0:\n",
        "                val_loss = evaluating(model, dev_data, criterion, device)\n",
        "                m, s = calculate_time(start)\n",
        "                train_loss_list.append(running_loss / len(train_data))\n",
        "                val_loss_list.append(val_loss)\n",
        "                print('%d/%d, (%dm%ds), train loss: %.3f, val loss: %.3f' %\n",
        "                      (epoch + 1, n_epochs, m, s, running_loss / len(train_data), val_loss))\n",
        "                if min_loss is None or min_loss > val_loss:\n",
        "                    if min_loss:\n",
        "                        print('Validation loss decreaseing: %.4f --> %.4f' % (min_loss, val_loss))\n",
        "                    else:\n",
        "                        print('Validation loss in first epoch is: %.4f' % (val_loss))\n",
        "                    print('Saving model')\n",
        "                    min_loss = val_loss\n",
        "                    torch.save(model, path)\n",
        "                running_loss = 0.0\n",
        "                model.train()\n",
        "    return train_loss_list, val_loss_list\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    n_epochs = 10\n",
        "    max_seq = 100\n",
        "    optim_name = 'Adam'\n",
        "    print('Loading Multi30K dataset')\n",
        "    train_data = torch.load('train_loader.pt')\n",
        "    dev_data = torch.load('dev_loader.pt')\n",
        "    test_data = torch.load('test_loader.pt')\n",
        "    src_vocab2num = torch.load('src_vocab2num.pt')\n",
        "    trg_vocab2num = torch.load('trg_vocab2num.pt')\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = TransformerModel(len(src_vocab2num), len(trg_vocab2num), 512, 1, n_encoders=6, n_decoders=6, d_ff=2048).to(device)\n",
        "    path = 'best_adam_transformer.pt'\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "    adam_optim = optim.Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-9)\n",
        "    optimizer = TransformerOptim(adam_optim)\n",
        "    print('Start training')\n",
        "    start = time.time()\n",
        "    train_loss, val_loss = training(model, train_data, dev_data, n_epochs, criterion, optimizer, device, path)\n",
        "    m, s = calculate_time(start)\n",
        "    print('Training took %dm%ds' % (m, s))\n",
        "    print('Start testing')\n",
        "    model = torch.load(path)\n",
        "    model = model.to(device)\n",
        "    # test_loss = evaluating(model, test_data, criterion, device)\n",
        "    # print('Test loss: %.3f' % (test_loss))\n",
        "    print('Saving experiment result')\n",
        "    train_loss_path = optim_name + '_train_loss.pt'\n",
        "    val_loss_path = optim_name + '_val_loss.pt'\n",
        "    # test_loss_path = optim_name + '_test_loss.pt'\n",
        "    torch.save(train_loss, train_loss_path)\n",
        "    torch.save(val_loss, val_loss_path)\n",
        "    # torch.save(test_loss, test_loss_path)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Multi30K dataset\n",
            "Start training\n",
            "1/10, (1m57s), train loss: 2.782, val loss: 1.435\n",
            "Validation loss in first epoch is: 1.4349\n",
            "Saving model\n",
            "2/10, (3m55s), train loss: 1.256, val loss: 1.063\n",
            "Validation loss decreaseing: 1.4349 --> 1.0628\n",
            "Saving model\n",
            "3/10, (5m53s), train loss: 1.002, val loss: 0.899\n",
            "Validation loss decreaseing: 1.0628 --> 0.8986\n",
            "Saving model\n",
            "4/10, (7m51s), train loss: 0.864, val loss: 0.792\n",
            "Validation loss decreaseing: 0.8986 --> 0.7920\n",
            "Saving model\n",
            "5/10, (9m49s), train loss: 0.762, val loss: 0.750\n",
            "Validation loss decreaseing: 0.7920 --> 0.7504\n",
            "Saving model\n",
            "6/10, (11m47s), train loss: 0.685, val loss: 0.734\n",
            "Validation loss decreaseing: 0.7504 --> 0.7340\n",
            "Saving model\n",
            "7/10, (13m45s), train loss: 0.622, val loss: 0.744\n",
            "8/10, (15m42s), train loss: 0.571, val loss: 0.675\n",
            "Validation loss decreaseing: 0.7340 --> 0.6755\n",
            "Saving model\n",
            "9/10, (17m41s), train loss: 0.527, val loss: 0.672\n",
            "Validation loss decreaseing: 0.6755 --> 0.6718\n",
            "Saving model\n",
            "10/10, (19m39s), train loss: 0.489, val loss: 0.711\n",
            "Training took 19m39s\n",
            "Start testing\n",
            "Saving experiment result\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1hUw3mVb_QS"
      },
      "source": [
        "def translate(model, sentence, trg_num2vocab, device):\n",
        "    model.eval()\n",
        "    sentence = tokenize_en(sentence[0])\n",
        "    tmp = []\n",
        "    for token in sentence:\n",
        "        if token in src_vocab2num:\n",
        "            tmp.append(src_vocab2num[token])\n",
        "        else:\n",
        "            tmp.append(src_vocab2num['<unk>'])\n",
        "    sentence = torch.LongTensor([tmp]).to(device)\n",
        "    sentence = sentence.view(1, -1)\n",
        "    trg_init_tok = trg_vocab2num[BOS]\n",
        "    trg = torch.LongTensor([[trg_init_tok]]).to(device)\n",
        "    translation = \"\"\n",
        "    for i in range(max_seq):\n",
        "        pred = model(sentence, trg)\n",
        "        pred = torch.argmax(pred, dim=1)\n",
        "        new_word = pred[0][i].item()\n",
        "        add_word = trg_num2vocab[new_word]\n",
        "        if add_word == EOS or add_word == PAD:\n",
        "            break\n",
        "        translation += \" \" + add_word\n",
        "        pred = torch.LongTensor([[new_word]]).to(device)\n",
        "        trg = torch.cat((trg, pred), dim=1).to(device)\n",
        "    \n",
        "    return translation"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoEhAqFRL2ua"
      },
      "source": [
        "def reconstructTrgLine(raw_data, num2vocab):\n",
        "    sentences = []\n",
        "    for line in raw_data:\n",
        "        tmp = ''\n",
        "        for token in line:\n",
        "            if token != BOS and token != EOS and token != PAD:\n",
        "                token = token + ' '\n",
        "                tmp += token\n",
        "        sentences.append([tmp])\n",
        "    \n",
        "    return sentences"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdy3vpP-jdkS"
      },
      "source": [
        "def reconstructSrcLine(data, num2vocab):\n",
        "    sentences = []\n",
        "    for line in data:\n",
        "        tmp = ''\n",
        "        for token in line:\n",
        "            word = num2vocab[token.item()]\n",
        "            if word != BOS and word != EOS and word != PAD and word != '<unk>':\n",
        "                word += ' '\n",
        "                tmp += word\n",
        "        sentences.append([tmp])\n",
        "    \n",
        "    return sentences"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RQfvlHyh-mK"
      },
      "source": [
        "raw_test_trg_sentences = reconstructLine(raw_test_trg, TGT.vocab.stoi)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si-lAM15iU5-"
      },
      "source": [
        "raw_test_src_sentences = reconstructSrcLine(src_test_data, SRC.vocab.itos)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TT5-D6xok43K",
        "outputId": "fddaeb54-e306-4d77-c0e6-e0af43affde3"
      },
      "source": [
        "pip install pytorch-nlp"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl (90kB)\n",
            "\r\u001b[K     |███▋                            | 10kB 22.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 20kB 18.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30kB 14.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 40kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 51kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 61kB 11.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 71kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 81kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (4.41.1)\n",
            "Installing collected packages: pytorch-nlp\n",
            "Successfully installed pytorch-nlp-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifmz17kTlssi"
      },
      "source": [
        "from torchnlp.metrics import get_moses_multi_bleu\n",
        "\n",
        "model = torch.load('best_adam_transformer.pt')\n",
        "translation = [None] * len(raw_test_src_sentences)\n",
        "for i in range(len(translation)):\n",
        "    translation[i] = [translate(model, raw_test_src_sentences[i], TGT.vocab.itos, device)]\n",
        "    if i == 3:\n",
        "        break"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juQhTmjvnIl2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}