{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUo4_yooRC8G",
        "outputId": "c7a08345-db1e-4f47-ec15-9a6b1fd52ec6"
      },
      "source": [
        "!pip install spacy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.11.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7NK-CXARKLv"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRbXFcYtRMyy",
        "outputId": "5141da8d-6ce8-4524-e6a2-1203c827794e"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (50.3.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbsBtT5HR-y2",
        "outputId": "3812ba37-52ab-4158-e763-9340afd65407"
      },
      "source": [
        "!python -m spacy download de"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting de_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 782kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (50.3.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp36-none-any.whl size=14907056 sha256=1e9c528d9790a6ba3568db66e3df40ed65ca1f357135297edc27dc045acec7df\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-syahoig5/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsgpDkyogrzG",
        "outputId": "8775dee7-5550-4670-fe1c-ade9845013cc"
      },
      "source": [
        "import spacy\n",
        "from torchtext.data import Field\n",
        "from torchtext.datasets import IWSLT\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "spacy_de = spacy.load('de')\n",
        "spacy_en = spacy.load('en')\n",
        "\n",
        "def tokenize_de(text):\n",
        "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "print('Loading dataset')\n",
        "BOS_WORD = '<s>'\n",
        "EOS_WORD = '</s>'\n",
        "BLANK_WORD = \"<pad>\"\n",
        "SRC = Field(tokenize=tokenize_en, pad_token=BLANK_WORD)\n",
        "TGT = Field(tokenize=tokenize_de, init_token=BOS_WORD, eos_token = EOS_WORD, pad_token=BLANK_WORD)\n",
        "max_seq = 30\n",
        "train, dev, test = IWSLT.splits(exts=('.en', '.de'), fields=(SRC, TGT), filter_pred=lambda x: len(vars(x)['src']) <= max_seq and len(vars(x)['trg']) <= max_seq)\n",
        "\n",
        "min_freq = 2\n",
        "batch_size = 100\n",
        "SRC.build_vocab(train.src, min_freq=min_freq)\n",
        "TGT.build_vocab(train.trg, min_freq=min_freq)\n",
        "\n",
        "src_vocab = SRC.vocab\n",
        "trg_vocab = TGT.vocab\n",
        "src_train_data = torch.ones(len(train), max_seq)\n",
        "trg_train_data = torch.ones(len(train), max_seq)\n",
        "src_dev_data = torch.ones(len(dev), max_seq)\n",
        "trg_dev_data = torch.ones(len(dev), max_seq)\n",
        "src_test_data = torch.ones(len(test), max_seq)\n",
        "raw_test_trg = []\n",
        "\n",
        "for i, sentence in enumerate(train):\n",
        "    for j, word in enumerate(sentence.src):\n",
        "        src_train_data[i][j] = src_vocab.stoi[word]\n",
        "\n",
        "    for j, word in enumerate(sentence.trg):\n",
        "        trg_train_data[i][j] = trg_vocab.stoi[word]\n",
        "\n",
        "for i, sentence in enumerate(dev):\n",
        "    for j, word in enumerate(sentence.src):\n",
        "        if word in src_vocab.stoi:\n",
        "            src_dev_data[i][j] = src_vocab.stoi[word]\n",
        "        else:\n",
        "            src_dev_data[i][j] = 0\n",
        "\n",
        "    for j, word in enumerate(sentence.trg):\n",
        "        if word in trg_vocab.stoi:\n",
        "            trg_dev_data[i][j] = trg_vocab.stoi[word]\n",
        "        else:\n",
        "            trg_dev_data[i][j] = 0\n",
        "\n",
        "for i, sentence in enumerate(test):\n",
        "    for j, word in enumerate(sentence.src):\n",
        "        if word in src_vocab.stoi:\n",
        "            src_test_data[i][j] = src_vocab.stoi[word]\n",
        "        else:\n",
        "            src_test_data[i][j] = 0\n",
        "\n",
        "    raw_test_trg.append(sentence.trg)\n",
        "\n",
        "src_train_data, trg_train_data = src_train_data.type(torch.long), trg_train_data.type(torch.long)\n",
        "src_dev_data, trg_dev_data = src_dev_data.type(torch.long), trg_dev_data.type(torch.long)\n",
        "src_test_data = src_test_data.type(torch.long)\n",
        "\n",
        "print('Building dataset')\n",
        "train = TensorDataset(src_train_data, trg_train_data)\n",
        "dev = TensorDataset(src_dev_data, trg_dev_data)\n",
        "test = TensorDataset(src_test_data)\n",
        "\n",
        "print('Building dataloader')\n",
        "train_loader = DataLoader(train, batch_size=batch_size, pin_memory=True)\n",
        "dev_loader = DataLoader(dev, batch_size=batch_size, pin_memory=True)\n",
        "test_loader = DataLoader(test, batch_size=batch_size, pin_memory=True)\n",
        "\n",
        "print('Saving dataloader')\n",
        "torch.save(src_vocab.stoi, 'src_vocab2num.pt')\n",
        "torch.save(src_vocab.itos, 'src_num2vocab.pt')\n",
        "torch.save(trg_vocab.stoi, 'trg_vocab2num.pt')\n",
        "torch.save(trg_vocab.itos, 'trg_num2vocab.pt')\n",
        "torch.save(raw_test_trg, 'raw_test_trg.pt')\n",
        "torch.save(train_loader, 'train_loader.pt')\n",
        "torch.save(dev_loader, 'dev_loader.pt')\n",
        "torch.save(test_loader, 'test_loader.pt')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset\n",
            "downloading en-de.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "en-de.tgz: 100%|██████████| 23.6M/23.6M [00:12<00:00, 1.86MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".data/iwslt/en-de/IWSLT16.TED.tst2014.en-de.de.xml\n",
            ".data/iwslt/en-de/IWSLT16.TED.dev2010.en-de.en.xml\n",
            ".data/iwslt/en-de/IWSLT16.TED.tst2011.en-de.de.xml\n",
            ".data/iwslt/en-de/IWSLT16.TED.tst2013.en-de.en.xml\n",
            ".data/iwslt/en-de/IWSLT16.TED.tst2012.en-de.de.xml\n",
            ".data/iwslt/en-de/IWSLT16.TED.dev2010.en-de.de.xml\n",
            ".data/iwslt/en-de/IWSLT16.TED.tst2013.en-de.de.xml\n",
            ".data/iwslt/en-de/IWSLT16.TED.tst2011.en-de.en.xml\n",
            ".data/iwslt/en-de/IWSLT16.TED.tst2012.en-de.en.xml\n",
            ".data/iwslt/en-de/IWSLT16.TED.tst2010.en-de.en.xml\n",
            ".data/iwslt/en-de/IWSLT16.TED.tst2010.en-de.de.xml\n",
            ".data/iwslt/en-de/IWSLT16.TED.tst2014.en-de.en.xml\n",
            ".data/iwslt/en-de/train.tags.en-de.de\n",
            ".data/iwslt/en-de/train.tags.en-de.en\n",
            "Building dataset\n",
            "Building dataloader\n",
            "Saving dataloader\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDYFUO1shoEQ",
        "outputId": "48db39cd-d75c-4fe4-d387-3a325acbd50f"
      },
      "source": [
        "\"\"\"\n",
        "Author: Yanting Miao\n",
        "\"\"\"\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from Model_Pytorch import TransformerModel\n",
        "from Optim import TransformerOptim\n",
        "\n",
        "def embedding(x, n_vocab, device, d_model=512):\n",
        "    embed = nn.Embedding(n_vocab, d_model, padding_idx=0).to(device)\n",
        "    return embed(x).permute(1, 0, 2)\n",
        "\n",
        "def calculate_time(start):\n",
        "    end = time.time()\n",
        "    t = end - start\n",
        "    m = t // 60\n",
        "    s = t - m * 60\n",
        "    return m, s\n",
        "\n",
        "def evaluating(model, data, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for src, trg in data:\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "            trg_input = trg[:, :-1]\n",
        "            trg_real = trg[:, 1:]\n",
        "            translate = model(src, trg_input)\n",
        "            loss = criterion(translate, trg_real)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(data)\n",
        "\n",
        "def training(model, train_data, dev_data, n_epochs, criterion, optimizer, device, path):\n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "    model.train()\n",
        "    step = 1\n",
        "    print_every = len(train_data)\n",
        "    min_loss = None\n",
        "    start = time.time()\n",
        "    for epoch in range(n_epochs):\n",
        "        running_loss = 0.0\n",
        "        for src, trg in train_data:\n",
        "            optimizer.zero_grad()\n",
        "            src = src.to(device)\n",
        "            # shifted to right, for example, trg = \"<s>I love cats</s>\", trg_input = \"<s>I love cats\", trg_real = \"I love cats</s>\"\n",
        "            trg_input = trg[:, :-1].to(device)\n",
        "            trg_real = trg[:, 1:].to(device)\n",
        "            translate = model(src, trg_input)\n",
        "            loss = criterion(translate, trg_real)\n",
        "            running_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            step += 1\n",
        "            if step % print_every == 0:\n",
        "                val_loss = evaluating(model, dev_data, criterion, device)\n",
        "                m, s = calculate_time(start)\n",
        "                train_loss_list.append(running_loss / len(train_data))\n",
        "                val_loss_list.append(val_loss)\n",
        "                print('%d/%d, (%dm%ds), train loss: %.3f, val loss: %.3f' %\n",
        "                      (epoch + 1, n_epochs, m, s, running_loss / len(train_data), val_loss))\n",
        "                if min_loss is None or min_loss > val_loss:\n",
        "                    if min_loss:\n",
        "                        print('Validation loss decreaseing: %.4f --> %.4f' % (min_loss, val_loss))\n",
        "                    else:\n",
        "                        print('Validation loss in first epoch is: %.4f' % (val_loss))\n",
        "                    min_loss = val_loss\n",
        "                    torch.save(model, path)\n",
        "                running_loss = 0.0\n",
        "                model.train()\n",
        "    return train_loss_list, val_loss_list\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    n_epochs = 10\n",
        "    max_seq = 30\n",
        "    optim_name = 'Adam'\n",
        "    print('Loading IWSLT dataset')\n",
        "    train_data = torch.load('train_loader.pt')\n",
        "    dev_data = torch.load('dev_loader.pt')\n",
        "    test_data = torch.load('test_loader.pt')\n",
        "    src_vocab2num = torch.load('src_vocab2num.pt')\n",
        "    trg_vocab2num = torch.load('trg_vocab2num.pt')\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = TransformerModel(len(src_vocab2num), len(trg_vocab2num), 512, 1, 1, 1, d_ff=1024).to(device)\n",
        "    path = 'best_adam_transformer.pt'\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "    adam_optim = optim.Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-9)\n",
        "    optimizer = TransformerOptim(adam_optim)\n",
        "    print('Start training')\n",
        "    start = time.time()\n",
        "    train_loss, val_loss = training(model, train_data, dev_data, n_epochs, criterion, optimizer, device, path)\n",
        "    m, s = calculate_time(start)\n",
        "    print('Training took %dm%ds' % (m, s))\n",
        "    print('Start testing')\n",
        "    model = torch.load(path)\n",
        "    model = model.to(device)\n",
        "    # test_loss = evaluating(model, test_data, criterion, device)\n",
        "    # print('Test loss: %.3f' % (test_loss))\n",
        "    print('Saving experiment result')\n",
        "    train_loss_path = optim_name + '_train_loss.pt'\n",
        "    val_loss_path = optim_name + '_val_loss.pt'\n",
        "    # test_loss_path = optim_name + '_test_loss.pt'\n",
        "    torch.save(train_loss, train_loss_path)\n",
        "    torch.save(val_loss, val_loss_path)\n",
        "    # torch.save(test_loss, test_loss_path)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading IWSLT dataset\n",
            "Start training\n",
            "1/10, (6m12s), train loss: 3.317, val loss: 2.122\n",
            "Validation loss in first epoch is: 2.1215\n",
            "2/10, (12m22s), train loss: 2.068, val loss: 1.775\n",
            "Validation loss decreaseing: 2.1215 --> 1.7746\n",
            "3/10, (18m33s), train loss: 1.789, val loss: 1.589\n",
            "Validation loss decreaseing: 1.7746 --> 1.5889\n",
            "4/10, (24m43s), train loss: 1.568, val loss: 1.457\n",
            "Validation loss decreaseing: 1.5889 --> 1.4573\n",
            "5/10, (30m54s), train loss: 1.420, val loss: 1.384\n",
            "Validation loss decreaseing: 1.4573 --> 1.3843\n",
            "6/10, (37m4s), train loss: 1.323, val loss: 1.333\n",
            "Validation loss decreaseing: 1.3843 --> 1.3328\n",
            "7/10, (43m15s), train loss: 1.254, val loss: 1.302\n",
            "Validation loss decreaseing: 1.3328 --> 1.3022\n",
            "8/10, (49m26s), train loss: 1.202, val loss: 1.276\n",
            "Validation loss decreaseing: 1.3022 --> 1.2760\n",
            "9/10, (55m36s), train loss: 1.163, val loss: 1.263\n",
            "Validation loss decreaseing: 1.2760 --> 1.2625\n",
            "10/10, (61m47s), train loss: 1.129, val loss: 1.241\n",
            "Validation loss decreaseing: 1.2625 --> 1.2414\n",
            "Training took 61m49s\n",
            "Start testing\n",
            "Saving experiment result\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CFmH68ohwOu"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}